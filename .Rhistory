library(tidyverse)
df <- Howell1 %>% filter(age > 0)
df_men <- filter(df, male == 1)
df_women <- filter(df, male == 0)
options(scipen=999999)
bayes_t <- BESTmcmc(df_men$weight, df_women$weight, rnd.seed = 1234)
View(df)
bayes_t <- BESTmcmc(filter(df_men, age >= 50)$height, filter(df_men, age < 50)$height, rnd.seed = 1234)
plotAll(bayes_t)
library(rstanarm)
library(rstanarm)
?install.packages
install.packages("rstanarm")
df <- Howell1 %>% filter(age > 18)
lm <- lm(height ~ male, df)
lm
summary(l)
plot(l)
lm <- lm(height ~ Howell1, df)
lm <- lm(height ~ male, Howell1)
summary(l)
lm <- lm(height ~ male, df)
tidy(lm)
library(tidyr)
tidy(lm)
library(tidyverse)
tidy(lm)
clear
summary(l)
lm <- lm(height ~ male, df)
summary(lm)
plot(lm)
lm
lm <- lm(height ~ weight + male, df)
lm
View(df)
l <- lm(height ~ weight*male)
l <- lm(height ~ weight*male, df)
l
plot(l)
summary(l)
library(tidyverse)
library(caret)
library(rpart)
library(randomForest)
library(AppliedPredictiveModelling)
library(AppliedPredictiveModeling)
library(party)
library(partykit)
library(partykit)
library(rpart)
data("solubility")
str(solubility)
solubility <- data("solubility")
str(solubility)
library(tidyverse)
library(AppliedPredictiveModeling)
library(caret)
library(party)
library(partykit)
library(rpart)
library(randomForest)
data("solubility")
View(solTrainX)
?rpart
rpart <- (solTrainY ~ ., data = solTrainX)
as.party(rpart <- (solTrainY ~ ., data = solTrainX))
head(solTrainY)
as.party(rpart(solTrainY ~ ., data = solTrainX))
plot(as.party(rpart(solTrainY ~ ., data = solTrainX)))
?as.party
train(solTrainY ~ ., data = solTrainX, method = "rpart1SE")
?train
tt <- train(solTrainY ~ ., data = solTrainX, method = "rpart1SE",
trControl = trainControl(method = "cv"))
tt <- train(solTrainX, solTrainY, method = "rpart1SE",
trControl = trainControl(method = "cv"))
tt
print(tt$finalModel)
plot(tt$finalModel)
plot(tt$finalModel) + text()
plot(tt$finalModel)
text()
plot(tt$finalModel)
text(tt$finalModel)
tt_vi <- varImp(tt)$importance %>%
mutate(vars = row.names(.)) %>%
arrange(desc(Overall)) %>%
top_n(20)
tt_vi
plot(tt_vi)
ggplot(tt_vi, aes(x = Overall, y = reorder(vars, Overall))) +
geom_segment(aes(yend = vars), xend = 0) +
geom_point() +
theme_bw() +
ylab("Variables")
ggplot(tt_vi, aes(x = Overall, y = reorder(vars, Overall))) +
geom_segment(aes(yend = vars), xend = 0) +
#geom_point() +
theme_bw() +
ylab("Variables")
ggplot(tt_vi, aes(x = Overall, y = reorder(vars, Overall))) +
geom_segment(aes(yend = vars), xend = 0) +
geom_point() +
theme_bw() +
ylab("Variables")
cor(solTrainX$SurfaceArea1, solTrainX$SurfaceArea2)
temp <- tempfile()
download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/00288/leaf.zip", temp)
temp <- tempfile()
download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/00288/leaf.zip", temp)
temp <- tempfile()
download.file("leaf.zip", temp)
leaves <- read_csv(unz(temp, "leaf.csv"),
col_names = c("Class",
"Specimen",
"Eccent",
"Aspect",
"Length",
"Solidity",
"Convexity",
"Iso",
"Max_Depth",
"Lobe",
"Intensity",
"Contrast",
"Smooth",
"Moment",
"Uniformity",
"Entropy"))
temp <- tempfile()
download.file("leaf.zip", temp)
?download.file
leaves <- read_csv(unz("file.zip", "leaf.csv"),
col_names = c("Class",
"Specimen",
"Eccent",
"Aspect",
"Length",
"Solidity",
"Convexity",
"Iso",
"Max_Depth",
"Lobe",
"Intensity",
"Contrast",
"Smooth",
"Moment",
"Uniformity",
"Entropy"))
?file
?unz
leaves <- read_csv(unz(filename = "file.zip", "leaf.csv"),
col_names = c("Class",
"Specimen",
"Eccent",
"Aspect",
"Length",
"Solidity",
"Convexity",
"Iso",
"Max_Depth",
"Lobe",
"Intensity",
"Contrast",
"Smooth",
"Moment",
"Uniformity",
"Entropy"))
leaves <- "leaf.csv"
leaf <- read.csv("~/Curso_Estatistica/leaf.csv", header=FALSE)
View(leaf)
leaves <- str(leaf)
View(leaf)
View(leaf)
leaves <- read_csv("leaf.csv",
col_names = c("Class",
"Specimen",
"Eccent",
"Aspect",
"Length",
"Solidity",
"Convexity",
"Iso",
"Max_Depth",
"Lobe",
"Intensity",
"Contrast",
"Smooth",
"Moment",
"Uniformity",
"Entropy"))
View(leaves)
View(leaves)
factor(leaves$Class)
y <- factor(leaves$Class)
createDataPartition(y,  = .8, list = FALSE, times = 1)
createDataPartition(y,  p = .8, list = FALSE, times = 1)
dp <- createDataPartition(y,  p = .8, list = FALSE, times = 1)
trainIndex <- createDataPartition(y,  p = .8, list = FALSE, times = 1)
trainIndex <- createDataPartition(leaves$Class,  p = .8, list = FALSE, times = 1)
leavesTrain <- leaves[trainIndex,]
controle <- trainControl(method = "cv", number = 10)
rfModel <- train(Class ~ ., data = leavesTrain, method = "rf", trControl = controle, importance = TRUE)
gbmModel <- train(Class ~ ., data = leavesTrain, method = "gbm", trControl = controle, importance = TRUE)
gbmModel <- train(Class ~ ., data = leavesTrain, method = "gbm", trControl = controle, importance = TRUE)
gbmModel <- train(Class ~ ., data = leavesTrain, method = "gbm", trControl = controle)
comp <- resamples(list(samp_RF = rfModel,
samp_GBM = gbmModel))
difference <- diff(comp)
summary(difference)
varImp(rfModel)
tt_vi_rf <- varImp(rfModel)$importance %>%
mutate(vars = row.names(.)) %>%
arrange(desc(Overall)) %>%
top_n(20)
ggplot(tt_vi_rf, aes(x = Overall, y = reorder(vars, Overall))) +
geom_segment(aes(yend = vars), xend = 0) +
geom_point() +
theme_bw() +
ylab("Variables")
tt_vi_gbm <- varImp(gbmModel)$importance %>%
mutate(vars = row.names(.)) %>%
arrange(desc(Overall)) %>%
top_n(20)
ggplot(tt_vi_gbm, aes(x = Overall, y = reorder(vars, Overall))) +
geom_segment(aes(yend = vars), xend = 0) +
geom_point() +
theme_bw() +
ylab("Variables")
checkImportance <- function(model){
tt_vi <- varImp(model)$importance %>%
mutate(vars = row.names(.)) %>%
arrange(desc(Overall)) %>%
top_n(20)
ggplot(tt_vi, aes(x = Overall, y = reorder(vars, Overall))) +
geom_segment(aes(yend = vars), xend = 0) +
geom_point() +
theme_bw() +
ylab("Variables")
}
checkImportance(gbmModel)
checkImportance(rfModel)
summary(difference)
difference
leaves$Class <- as.factor(leaves$Class)
View(leaves)
trainIndex <- createDataPartition(leaves$Class,  p = .8, list = FALSE, times = 1)
leavesTrain <- leaves[trainIndex,]
controle <- trainControl(method = "cv", number = 10)
rfModel <- train(Class ~ ., data = leavesTrain, method = "rf", trControl = controle, importance = TRUE)
gbmModel <- train(Class ~ ., data = leavesTrain, method = "gbm", trControl = controle)
# Comparação entre métodos
comp <- resamples(list(samp_RF = rfModel,
samp_GBM = gbmModel))
difference <- diff(comp)
summary(difference)
# Importância das variáveis
checkImportance(rfModel)
checkImportance(gbmModel)
checkImportance(rfModel)
checkImportance <- function(model){
tt_vi <- varImp(model)$importance %>%
mutate(vars = row.names(.)) %>%
arrange(desc(Overall)) %>%
top_n(20)
ggplot(tt_vi, aes(x = Overall, y = reorder(vars, Overall))) +
geom_segment(aes(yend = vars), xend = 0) +
geom_point() +
theme_bw() +
ylab("Variables")
}
checkImportance(rfModel)
checkImportance(rfModel)
checkImportance <- function(model){
tt_vi <- varImp(model)$importance %>%
mutate(vars = row.names(.)) %>%
arrange(desc("Overall")) %>%
top_n(20)
ggplot(tt_vi, aes(x = Overall, y = reorder(vars, Overall))) +
geom_segment(aes(yend = vars), xend = 0) +
geom_point() +
theme_bw() +
ylab("Variables")
}
checkImportance(rfModel)
leavesTest <- leaves[-trainIndex,]
predito_rf <- predict(rfModel, newdata=leavesTest)
predito_gbm <- predict(gbmModel, newdata=leavesTest)
confusionMatrix(predito_rf, leavesTest$Class)
confusionMatrix(predito_gbm, leavesTest$Class)
postResample(predito_rf, leavesTest$Class)
postResample(predito_gbm, leavesTest$Class)
library(mlbench)
set.seed(200)
simulated <- mlbench.friedman1(200, sd = 1)
simulated <- as_data_frame(simulated$x, simulated$y)
colnames(simulated)[10] <- "y"
View(simulated)
checkImportance <- function(model){
tt_vi <- varImp(model)$importance
tt_vi <- mutate(vars = row.names(.)) %>%
arrange(desc(tt_vi$Overall)) %>%
top_n(20)
ggplot(tt_vi, aes(x = Overall, y = reorder(vars, Overall))) +
geom_segment(aes(yend = vars), xend = 0) +
geom_point() +
theme_bw() +
ylab("Variables")
}
checkImportance(rfModel)
checkImportance <- function(model){
tt_vi <- varImp(model)$importance
tt_vi <- mutate(tt_vi, vars = row.names(.)) %>%
arrange(desc(tt_vi$Overall)) %>%
top_n(20)
ggplot(tt_vi, aes(x = Overall, y = reorder(vars, Overall))) +
geom_segment(aes(yend = vars), xend = 0) +
geom_point() +
theme_bw() +
ylab("Variables")
}
checkImportance(rfModel)
tt_vi <- varImp(rfModel)$importance
tt_vi
varImp(rfModel)
varImp(gbmModel)
rfModel <- train(Class ~ ., data = leavesTrain, method = "rf", trControl = controle, importance = TRUE)
varImp(rfModel)
varImp(rfModel)$importance
varImp(rfModel)$importance %>% mutate(vars = row.names(.))
library(tidyverse)
library(AppliedPredictiveModeling)
library(caret)
library(party)
library(partykit)
library(rpart)
library(randomForest)
leaves <- read_csv("leaf.csv",
col_names = c("Class",
"Specimen",
"Eccent",
"Aspect",
"Length",
"Solidity",
"Convexity",
"Iso",
"Max_Depth",
"Lobe",
"Intensity",
"Contrast",
"Smooth",
"Moment",
"Uniformity",
"Entropy")
)
leaves$Class <- as.factor(leaves$Class)
trainIndex <- createDataPartition(leaves$Class,  p = .8, list = FALSE, times = 1)
leavesTrain <- leaves[trainIndex,]
controle <- trainControl(method = "cv", number = 10)
rfModel <- train(Class ~ ., data = leavesTrain, method = "rf", trControl = controle, importance = TRUE)
checkImportance(rfModel)
varImp(rfModel)$importance
varImp(rfModel)
checkImportance <- function(model){
tt_vi <- varImp(model)$importance %>%
mutate(vars = row.names(.)) %>%
arrange(desc(Overall)) %>%
top_n(20)
ggplot(tt_vi, aes(x = Overall, y = reorder(vars, Overall))) +
geom_segment(aes(yend = vars), xend = 0) +
geom_point() +
theme_bw() +
ylab("Variables")
}
gbmModel <- train(Class ~ ., data = leavesTrain, method = "gbm", trControl = controle)
checkImportance(gbmModel)
checkImportance(rfModel)
data("USArrests")
data("USArrests")
head(USArrests)
str(USArrests)
library(ggplot2)
?geom_text
View(USArrests)
ggplot(data=USArrests,
aes(x=UrbanPop, y=Murder)) +
geom_text(label = rownames(USArrests))
library(gridExtra)
teste1 <- ggplot(data=USArrests,
aes(x=UrbanPop, y=Murder)) +
geom_text(label = rownames(USArrests))
teste2 <- ggplot(data=USArrests,
aes(x=UrbanPop, y=Rape)) +
geom_text(label = rownames(USArrests))
grid.arrange(teste1, teste2)
View(USArrests)
ggplot(data=USArrests, aes(x=Rape, y=Murder)) +
geom_point() + geom_smooth(method="lm")
dados <- prcomp(t(USArrests), scale=T)
head(dados)
dados$rotation
dados$rotation[,1]
dados$rotation[,2]
dados$rotation
rownames(dados$rotation)
dados <- prcomp(t(USArrests), scale=T)
ggplot(data=NULL, aes(x=dados$rotation[,1],
y=dados$roation[,2])) +
geom_text(label = rownames(dados$roation))
library(tidyverse)
dados <- prcomp(t(USArrests), scale=T)
ggplot(data=NULL, aes(x=dados$rotation[,1],
y=dados$roation[,2]))
dados$rotation
ggplot(data=NULL, aes(x=dados$rotation[,1],
y=dados$roation[,2])) +
geom_text(aes(label = rownames(dados$roation)))
dados <- prcomp(t(USArrests), scale=T)
ggplot(data=NULL, aes(x=dados$rotation[,1],
y=dados$roation[,2])) +
geom_text(aes(label = rownames(dados$roation)))
readRDS('~/Downloads/votacao_camara/indice_legislador.rds')
readRDS('~/Downloads/Treinamento R/votacao_camara/indice_legislador.rds')
indice <- readRDS('~/Downloads/Treinamento R/votacao_camara/indice_legislador.rds')
votacoes <- readRDS('~/Downloads/Treinamento R/votacao_camara/votacao.rds')
View(votacoes)
View(indice)
d_legislador <- dist(votacoes)
head(d_legislador)
pca_deputados <- cmdscale(d_legislador)
pca_deputados <- data.frame(pca_deputados)
View(pca_deputados)
pca_deputados$id <- votacoes$id_legislator
View(pca_deputados)
View(indice)
indice <- readRDS('~/Downloads/Treinamento R/votacao_camara/indice_legislador.rds')
votacoes <- readRDS('~/Downloads/Treinamento R/votacao_camara/votacao.rds')
# Distância Euclidiana (Teorem. Pitágoras)
d_legislador <- dist(votacoes)
#PCA
pca_deputados <- cmdscale(d_legislador)
pca_deputados <- data.frame(pca_deputados)
str(indice)
indica <- indice[!duplicated(indice),]
indice <- indice[!duplicated(indice),]
pca_deputados$id_legislador <- votacoes$id_legislator
pca_deputados <- inner_join(pca_deputados, indice)
str(pca_deputados)
pca_deputados <- inner_join(pca_deputados, indice)
View(indice)
View(votacoes)
View(pca_deputados)
pca_deputados$id_legislator <- votacoes$id_legislator
pca_deputados <- select(pca_deputados, -id_legislador)
View(pca_deputados)
pca_deputados <- inner_join(pca_deputados, indice)
View(pca_deputados)
pca_deputados <- pca_deputados[!duplicated(pca_deputados),]
View(pca_deputados)
ggplot(pca_deputados, aes(x=X1,y=X2)) +
geom_text(aes(label = Partido), size = 2)
v <- .3
x <- matrix(c(.3,.5,1.6,.5,1,.8))
x <- matrix(c(.3,.5,1.6,.5,1,.8), ncol=2)
x1 <- c(rnorm(150,x[1,1],v), rnorm(150, x[2,1], rnorm(150, x[3,1], v)))
x2 <- c(rnorm(150,x[1,2],v), rnorm(150, x[2,2], rnorm(150, x[3,2], v)))
y <- c(rep("grupo1", 150),rep("grupo2", 150),rep("grupo3", 150))
dados <- data.frame(x1=x1,x2=x2,y=y)
x1 <- c(rnorm(150,x[1,1],v), rnorm(150, x[2,1]), rnorm(150, x[3,1], v))
x2 <- c(rnorm(150,x[1,2],v), rnorm(150, x[2,2]), rnorm(150, x[3,2], v))
y <- c(rep("grupo1", 150),rep("grupo2", 150),rep("grupo3", 150))
dados <- data.frame(x1=x1,x2=x2,y=y)
resultado <- kmeans(dados[,1:2],3)
dados$yhat <- resultado$cluster
View(dados)
cluster <- hclust(dist(dados[,1:2]), method="centroid") # O método pode variar, para fins de testes e verificação de qual se encaixa melhor no cenário
plot(cluster)
dados$hy <- cutree(cluster, 3)
g1 <- ggplot(dados, aes(x=x1,y=x2), colour = factor(y)) + geom_point()
g2 <- ggplot(dados, aes(x=x1,y=x2), colour = factor(yhat))
g3 <- ggplot(dados, aes(x=x1,y=x2), colour = factor(hy)) + geom_point()
grid.arrange(g1, g2, g3)
g1 <- ggplot(dados, aes(x=x1,y=x2, colour = factor(y))) + geom_point()
g2 <- ggplot(dados, aes(x=x1,y=x2, colour = factor(yhat)))
g3 <- ggplot(dados, aes(x=x1,y=x2, colour = factor(hy))) + geom_point()
grid.arrange(g1, g2, g3)
dados$yhat <- resultado$cluster
g2 <- ggplot(dados, aes(x=x1,y=x2, colour = factor(yhat)))
grid.arrange(g1, g2, g3)
resultado <- kmeans(dados[,1:2],3)
dados$yhat <- resultado$cluster
v <- .3
x <- matrix(c(.3,.5,1.6,.5,1,.8), ncol=2)
x1 <- c(rnorm(150,x[1,1],v), rnorm(150, x[2,1]), rnorm(150, x[3,1], v))
x2 <- c(rnorm(150,x[1,2],v), rnorm(150, x[2,2]), rnorm(150, x[3,2], v))
y <- c(rep("grupo1", 150),rep("grupo2", 150),rep("grupo3", 150))
dados <- data.frame(x1=x1,x2=x2,y=y)
g1 <- ggplot(dados, aes(x=x1,y=x2, colour = factor(y))) + geom_point()
# K-means
resultado <- kmeans(dados[,1:2],3)
dados$yhat <- resultado$cluster
g2 <- ggplot(dados, aes(x=x1,y=x2, colour = factor(yhat)))
# Hierarchical Cluster
cluster <- hclust(dist(dados[,1:2]), method="centroid") # O método pode variar, para fins de testes e verificação de qual se encaixa melhor no cenário
plot(cluster)
dados$hy <- cutree(cluster, 3)
g3 <- ggplot(dados, aes(x=x1,y=x2, colour = factor(hy))) + geom_point()
grid.arrange(g1, g2, g3)
View(dados)
g2 <- ggplot(dados, aes(x=x1,y=x2, colour = factor(yhat))) + geom_point()
grid.arrange(g1, g2, g3)
